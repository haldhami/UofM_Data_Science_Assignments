{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "_You are currently looking at **version 1.1** of this notebook. To download notebooks and datafiles, as well as get help on Jupyter notebooks in the Coursera platform, visit the [Jupyter Notebook FAQ](https://www.coursera.org/learn/python-social-network-analysis/resources/yPcBs) course resource._\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 - Creating and Manipulating Graphs\n",
    "\n",
    "Eight employees at a small company were asked to choose 3 movies that they would most enjoy watching for the upcoming company movie night. These choices are stored in the file `Employee_Movie_Choices.txt`.\n",
    "\n",
    "A second file, `Employee_Relationships.txt`, has data on the relationships between different coworkers. \n",
    "\n",
    "The relationship score has value of `-100` (Enemies) to `+100` (Best Friends). A value of zero means the two employees haven't interacted or are indifferent.\n",
    "\n",
    "Both files are tab delimited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from networkx.algorithms import bipartite\n",
    "\n",
    "\n",
    "# This is the set of employees\n",
    "employees = set(['Pablo',\n",
    "                 'Lee',\n",
    "                 'Georgia',\n",
    "                 'Vincent',\n",
    "                 'Andy',\n",
    "                 'Frida',\n",
    "                 'Joan',\n",
    "                 'Claude'])\n",
    "\n",
    "# This is the set of movies\n",
    "movies = set(['The Shawshank Redemption',\n",
    "              'Forrest Gump',\n",
    "              'The Matrix',\n",
    "              'Anaconda',\n",
    "              'The Social Network',\n",
    "              'The Godfather',\n",
    "              'Monty Python and the Holy Grail',\n",
    "              'Snakes on a Plane',\n",
    "              'Kung Fu Panda',\n",
    "              'The Dark Knight',\n",
    "              'Mean Girls'])\n",
    "\n",
    "\n",
    "# you can use the following function to plot graphs\n",
    "# make sure to comment it out before submitting to the autograder\n",
    "def plot_graph(G, weight_name=None):\n",
    "    '''\n",
    "    G: a networkx G\n",
    "    weight_name: name of the attribute for plotting edge weights (if G is weighted)\n",
    "    '''\n",
    "    %matplotlib notebook\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    plt.figure()\n",
    "    pos = nx.spring_layout(G)\n",
    "    edges = G.edges()\n",
    "    weights = None\n",
    "    \n",
    "    if weight_name:\n",
    "        weights = [int(G[u][v][weight_name]) for u,v in edges]\n",
    "        labels = nx.get_edge_attributes(G,weight_name)\n",
    "        nx.draw_networkx_edge_labels(G,pos,edge_labels=labels)\n",
    "        nx.draw_networkx(G, pos, edges=edges, width=weights);\n",
    "    else:\n",
    "        nx.draw_networkx(G, pos, edges=edges);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "Using NetworkX, load in the bipartite graph from `Employee_Movie_Choices.txt` and return that graph.\n",
    "\n",
    "*This function should return a networkx graph with 19 nodes and 24 edges*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def answer_one():\n",
    "        \n",
    "    # Create the graph using read_edgelist, and tab delimiter\n",
    "    G = nx.read_edgelist('Employee_Movie_Choices.txt', nodetype=str, delimiter='\\t', create_using=nx.Graph())\n",
    "    \n",
    "    # Separate the nodes into two partitions\n",
    "    G.add_nodes_from(employees, bipartite=0)\n",
    "    G.add_nodes_from(movies, bipartite=1)\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Using the graph from the previous question, add nodes attributes named `'type'` where movies have the value `'movie'` and employees have the value `'employee'` and return that graph.\n",
    "\n",
    "*This function should return a networkx graph with node attributes `{'type': 'movie'}` or `{'type': 'employee'}`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def answer_two():\n",
    "    \n",
    "    G = answer_one()\n",
    "    # Add node attributes to each set of nodes\n",
    "    G.add_nodes_from(employees, type='employee')\n",
    "    G.add_nodes_from(movies, type='movie')\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Question 3\n",
    "\n",
    "Find a weighted projection of the graph from `answer_two` which tells us how many movies different pairs of employees have in common.\n",
    "\n",
    "*This function should return a weighted projected graph.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def answer_three():\n",
    "        \n",
    "    G = answer_two()\n",
    "    # Create a weighted projected graph of the employees from G\n",
    "    P = bipartite.weighted_projected_graph(G, employees)\n",
    "    \n",
    "    return P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Question 4\n",
    "\n",
    "Suppose you'd like to find out if people that have a high relationship score also like the same types of movies.\n",
    "\n",
    "Find the Pearson correlation ( using `DataFrame.corr()` ) between employee relationship scores and the number of movies they have in common. If two employees have no movies in common it should be treated as a 0, not a missing value, and should be included in the correlation calculation.\n",
    "\n",
    "*This function should return a float.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def answer_four():\n",
    "    \n",
    "    def get_name_sets(df):\n",
    "        \"\"\"Take in employee movies similarities dataframe and create a dictionary of sets used to check if \n",
    "        they exist in employee relationships dataframe\"\"\"\n",
    "        name_sets = {}\n",
    "        for i, row in df.iterrows():\n",
    "            name1 = row['Name1']\n",
    "            name2 = row['Name2']\n",
    "            name_sets[i] = set([name1, name2])\n",
    "\n",
    "        return name_sets\n",
    "    \n",
    "    def add_common_movies(row):\n",
    "        \"\"\"Checks if row of employee relationships df contains two employees that share movie interests, \n",
    "        returns the value of movies if they do\"\"\"\n",
    "        name1 = row['Name1']\n",
    "        name2 = row['Name2']\n",
    "\n",
    "        # Create set of names in row\n",
    "        myset = {name1, name2}\n",
    "\n",
    "        # If myset in dict of sets, then obtain the key (index) value of the dict which will be used to obtain the\n",
    "        # films in common from the movie similarity df\n",
    "        if myset in name_sets.values():\n",
    "            index = list(name_sets.keys())[list(name_sets.values()).index(myset)]\n",
    "            return df1.iloc[index]['Weight']\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    P = answer_three()\n",
    "    # Read in P as dataframe and extract the weight value from the attributes column\n",
    "    df1 = pd.DataFrame(P.edges(data=True), columns=['Name1', 'Name2', 'Weight'])\n",
    "    df1['Weight'] = df1['Weight'].apply(lambda x: x['weight'])\n",
    "\n",
    "    # Read in employee relationships txt file\n",
    "    G_df = pd.read_csv('Employee_Relationships.txt', \n",
    "                       delimiter='\\t', header=None, names=['Name1', 'Name2', 'Friendship'])\n",
    "    \n",
    "    # Obtain name sets of employee movie similarities df\n",
    "    name_sets = get_name_sets(df1)\n",
    "    \n",
    "    # Create a new weight column in G_df using add_common_movies func\n",
    "    G_df['Weight'] = G_df.apply(add_common_movies, axis=1)\n",
    "    \n",
    "    # Calculate the pearson coefficient between two series\n",
    "    s1 = G_df['Friendship']\n",
    "    s2 = G_df['Weight']\n",
    "    \n",
    "    p_coeff = s1.corr(s2)\n",
    "    \n",
    "    return p_coeff\n"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-social-network-analysis",
   "graded_item_id": "YNa9b",
   "launcher_item_id": "hvNc1",
   "part_id": "VbyiB"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
